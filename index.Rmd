---
title: "Modelando la probabilidad de incumplimiento"
author: "Alondra Matos"
date: "2023-12-03"
output: 
  html_document:
    theme: cerulean
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE, comment=NA, message = FALSE)
```

### Descripción de la base de datos

```{r,echo=FALSE}
#setwd("D:/ComputoEstadistico/Proyecto")
setwd("C:/Users/Alondra/OneDrive/Escritorio/ComputoEstadistico/Proyecto/FINAL")
datos <- read.csv("C:/Users/Alondra/OneDrive/Escritorio/ComputoEstadistico/Proyecto/loan_data_2007_2014.csv")

### Variables a considerar
# Variables numéricas
numeric_var <- c("annual_inc","int_rate","mths_since_last_delinq",
               "mths_since_last_record")

# Variables que se utilizan para crear otras variabloes
auxiliar_var <- c("member_id","loan_status")

# Variables categóricas
nominal_var <- c("home_ownership", "addr_state", "verification_status", 
               "purpose","initial_list_status")

ordinal_var <-  c("grade", "term", "emp_length", "acc_now_delinq", "inq_last_6mths")

factor_var <- c(nominal_var, ordinal_var )
  
col_names <- c(factor_var, numeric_var, auxiliar_var)
datos <- datos[, col_names]

summary(datos)
head(datos,5)
```

#### Tratamiento de datos faltantes

*Visualización de datos faltantes*

Se comprueba la presencia de cadenas de texto vacías en alguna de las variables.

```{r}
# Contar cuántos valores son cadenas de texto vacías en cada columna
conteo_vacios <- apply(datos=="", 2, sum)

#Imprimir los resultados para cada columnas
for ( i in seq_along(conteo_vacios)){
  if(names(conteo_vacios)[i] %in% factor_var){
  cat("Variable ", names(conteo_vacios)[i],":", conteo_vacios[i], "\n")
  }
}

```

Se observa que *emp_length* es la única variable con cadenas vacías, las cuales se reemplazarán por "\< 1 year"-

```{r}
datos$emp_length[which(datos$emp_length=="")]="< 1 year"
```

La siguiente gráfica permite visualizar la distribución de valores perdidos en tu conjunto de datos.

```{r, echo=FALSE}
# Instalar el paquete (sólo necesario la primera vez)
#install.packages("naniar")

# Cargar el paquete
library(naniar)

# Visualizar valores perdidos
vis_miss(datos, warn_large_data = FALSE)
```

```{r}
datos$inq_last_6mths[which(is.na(datos$inq_last_6mths))]=0
datos$acc_now_delinq[which(is.na(datos$acc_now_delinq))]=0

# Eliminar las filas con NA en variable income
datos <- datos[complete.cases(datos$annual_inc), ]
```

```{r}
library(dplyr)

datos$emp_length[datos$emp_length == "10+ years"] <- "9+ years"
#datos$emp_length<- factor(datos$emp_length, levels = c("< 1 year",  "1 year","2 years" ,"3 years",   "4 years",   "5 years",   "6 years" ,"7 years",  "8 years", "9 years","10+ years"))

# Convertir las variables discretas en factores
datos <- datos %>%
  mutate_at(vars(factor_var), factor)


```

#### Creación de variables

*Variable de respuesta*

El estado de préstamo de cada cliente puede clasificarse en alguna de las siguientes categorías:

```{r, echo=FALSE}
unique(datos$loan_status)
```

Los clientes considerados malos son aquellos cuyo estatus de préstamo se encuentra entre:

-   Charged Off
-   Default
-   Does not meet the credit policy. Status:Charged Off
-   Late (31-120 days)

Se crea la variable de respuesta que clasifica a los clientes como buenos (1) o malos (0) en función de su historial crediticio. La proporción de buenos(1) y malos(0) es:

```{r}
nom_malos <- c("Charged Off","Default",
            "Does not meet the credit policy. Status:Charged Off",
            "Late (31-120 days)")

# Se agrega la variable de respuesta
datos$y <-ifelse(datos$loan_status%in%nom_malos,"0","1")

# Proporción de buenos(1) y malos(0)
freq_y <- table(datos[,"y"])
prop.table(freq_y)

```

#### Creación de los datos de entrenamiento y prueba

```{r, echo=FALSE}
# Aleatoriamente se toma el 80% de los datos sin reemplazo
set.seed(15)
idx_train <- sample.int(n=nrow(datos),size=nrow(datos)*0.8,replace = FALSE)
train <- datos[idx_train,]
test <- datos[-idx_train,]

# Importe a excel:
#write.csv(datos,"datos.csv")
#write.csv(train,"train.csv")
#write.csv(test,"test.csv")
```

### Tratamiento de variables discretas

#### Coarse Classing

El Coarse Classing consiste en agrupar categorías adyacentes con puntuaciones WOE similares, pues al tener proporciones similares de eventos y no eventos, ambas categorías exhiben un comportamiento similar. Para llevar a cabo esta técnica, es necesario cumplir con los siguientes criterios:

-   Cada categoría (intervalo) debe abarcar al menos el 5% de las observaciones.
-   Cada categoría (intervalo) debe tener una presencia distinta de cero tanto para eventos (por ejemplo, "clientes buenos") como para no eventos (por ejemplo, "clientes malos").
-   Las puntuaciones WOE deben ser diferentes para cada categoría, y se deben agrupar aquellas que sean similares.
-   Las puntuaciones WOE deben seguir una tendencia monótona, es decir, aumentar o disminuir de manera consistente a través de los grupos.
-   Los valores faltantes se agrupan de manera independiente.

```{r}
calculate_woe <- function(data, target_variable, name_vars ) {
  
  # Inicializar una lista para almacenar los resultados
  woe_list <- list()

  # Calcular WOE para cada variable categórica
  for (var in name_vars) {
    
    # Crear una tabla de contingencia
    table_var <- table(data[[var]], data[[target_variable]])

    # Calcular porcentajes de buenos y malos
    # Si un contenedor en particular no contiene ningún evento o ningún evento, se puede usar
    # la siguiente fórmula para ignorar el WOE faltante. Se suman 0,5 al número 
    # de eventos y no eventos en un grupo.
    
    bad <- table_var[, 2]
    good <- table_var[, 1]
    good_percentage <- (table_var[, 2] + 0.5 )/ sum(table_var[, 2])
    bad_percentage <- (table_var[, 1] + 0.5)/  sum(table_var[, 1])

    # Calcular WOE  ajustado
    woe <- log(good_percentage / bad_percentage)
    
    
  
    # Almacenar resultados en la lista
    woe_list[[var]]<- data.frame(
      Categoria = names(table_var[, 1]),
      WOE = woe,
      Total_buenos = good,
      Total_malos = bad,
      Total = good + bad,
      Total_porcentaje = (good + bad)/nrow(data)
      
     )
    
    if(var %in% c(nominal_var)){
     # Ordenar
      woe_list[[var]] <- woe_list[[var]][order(woe_list[[var]]$WOE), ]
    }
    else{
      woe_list[[var]] <- woe_list[[var]]
     }
      
  }

  # Devolver la lista de resultados
  return(woe_list)
}

# Funcion de la gráfica del WOE
plot_woe <- function(df,var_name ){
  plot(1:nrow(df), df$WOE, type = "o", col = "blue", xaxt = "n",
            xlab = "Clase",ylab ="WOE", main = paste("WOE de la variable",var_name))
  axis(1, labels = df$Categoria, at = 1:nrow(df)) 
}

# Obtener las variables categóricas
categorical_vars <- names(train)[sapply(train, function(x) is.factor(x) )]
categorical_vars <- categorical_vars[!categorical_vars %in% c("y","loan_status",
                                                               "issue_d", "earliest_cr_line")]
woe_results <- calculate_woe(train, "y", categorical_vars)

# Imprimir los resultados
for (i in seq_along(woe_results)) {
  cat("Variable:", names(woe_results)[i], "\n")
  print(woe_results[[i]])
  plot_woe(woe_results[[i]], var_name = names(woe_results)[i])
  cat("\n")
}

```

```{r}
are_similares <- function(df1, df2, threshold = 0.05) {
  # Verificar si dos filas son similares según puntuaciones WOE
  return(abs(tail(df1[,"WOE"], 1) - tail(df2[,"WOE"], 1)) <= threshold)
}

coarse_classing <- function(data, target, name_vars, threshold = 0.05, par_total_porcentaje = 0.05) {
  # Calcular las puntuaciones WOE
  woe_results <- calculate_woe(data, target, name_vars)
  
  # Inicializar lista de grupos
  grupos <- list()
  
  # Iterar sobre los resultados de WOE
  for (j in seq_along(woe_results)) {
    grupos[[j]] <- list()
    sorted_data <- woe_results[[j]]
    
    # Omitir si solo hay 2 categorías
    if (nrow(sorted_data) == 2) {
      grupos[[j]] <- sorted_data
      next
    }
    
    # Inicializar grupos para esta variable
    actual_grupo <- sorted_data[1, , drop = FALSE]
    k <- 1 # contador de elementos dentro de la lista de la variable
    
    # Iterar sobre las filas y agrupar categorías adyacentes con puntuaciones WOE similares
    for (i in 2:nrow(sorted_data)) {
      if (are_similares(sorted_data[i, , drop = FALSE], actual_grupo )) {
        if (sorted_data[i,"Total_porcentaje"] < par_total_porcentaje) {
          actual_grupo <- rbind(actual_grupo, sorted_data[i, , drop = FALSE])
        } else {
          grupos[[j]][[k]] <- actual_grupo
          actual_grupo <- sorted_data[i, , drop = FALSE]
          k <- k + 1
        }
      } else {
        if ((tail(actual_grupo[,"Total"], 1)/nrow(data)) > 0.05) {
          grupos[[j]][[k]] <- actual_grupo
          actual_grupo <- sorted_data[i, , drop = FALSE]
          k <- k + 1
        } else {
          if (sorted_data[i,"Total_porcentaje"] < 0.05) {
            actual_grupo <- rbind(actual_grupo, sorted_data[i, , drop = FALSE])
          } else {
            grupos[[j]][[k]] <- actual_grupo
            actual_grupo <- sorted_data[i, , drop = FALSE]
            k <- k + 1
          }
        }
      }
    }
    
    # Agregar el último grupo
    grupos[[j]][[k]] <- actual_grupo
    
    # Crear el dataframe de binning para cada grupo
    binning_df <- data.frame()
    
    for (h in seq_along(grupos[[j]])) {
      df <- grupos[[j]][[h]]
      Total_buenos <- sum(df$Total_buenos)
      Total_malos <- sum(df$Total_malos)
      Total <- sum(df$Total)
      
      binning_df <- rbind(binning_df, data.frame(
        Categoria = paste(df$Categoria, collapse = "_"),
        WOE = log((Total_buenos/sum(sorted_data[,"Total_buenos"])) /
                  (Total_malos/sum(sorted_data[,"Total_malos"]))),
        Total_buenos = Total_buenos,
        Total_malos = Total_malos,
        Total = Total,
        Total_porcentaje = Total/nrow(data)
      ))
    }
    
    Total_porcentaje <- binning_df[1, "Total_porcentaje"]
    new_binning_df <- list()
    new_binning <- binning_df[1, ]
    i <- 2
    r <- 1
    
  repeat {
    while (Total_porcentaje < 0.05) {
      new_binning <- rbind(new_binning, binning_df[i, ])
      Total_porcentaje <- Total_porcentaje + binning_df[i, "Total_porcentaje"]
      i <- i + 1

    if (i > nrow(binning_df)) {
      break
      }
    }
  
    new_binning_df[[r]] <- new_binning
    r <- r + 1

    if (i <= nrow(binning_df)) {
      new_binning <- binning_df[i, ]
      Total_porcentaje <- new_binning[1, "Total_porcentaje"]
      i <- i + 1
    }

    if (i > nrow(binning_df)) {
      break
    }
  }

  # Add the last binning_df if needed
  if (nrow(new_binning) > 0) {
    if(sum(new_binning[, "Total_porcentaje"])<0.05){
      new_binning_df[[r-1]] <- rbind(new_binning_df[[r-1]], new_binning )
    }else{
      if(!identical(new_binning_df[[r-1]],  new_binning)){
    new_binning_df[[r]] <- new_binning
      }
    }
  }
    
    # Create the dataframe of binning for each group
    binning_df_result <- data.frame()
    
    for (h in seq_along(new_binning_df)) {
      df <- new_binning_df[[h]]
      Total_buenos <- sum(df$Total_buenos)
      Total_malos <- sum(df$Total_malos)
      Total <- sum(df$Total)

      binning_df_result <- rbind(binning_df_result, 
                                 data.frame(Categoria = paste(df$Categoria, collapse = "_"),
                                            WOE = log((Total_buenos/sum(sorted_data[,"Total_buenos"])) /
                                                      (Total_malos/sum(sorted_data[,"Total_malos"]))),
                                            Total_buenos = Total_buenos,
                                            Total_malos = Total_malos,
                                            Total = Total,
                                            Total_porcentaje = Total/nrow(data)
                                 ))
    }
    
    grupos[[j]] <- binning_df_result
  }
  
  # Asignar nombres a la lista
  names(grupos) <- name_vars
  
  return(grupos)
}

```

```{r}
coarse_classing_results <- coarse_classing(train, "y",threshold = 0.15,categorical_vars, 0.1)

categoric_label <- list()
# Imprimir los resultados
for (i in 1:length(coarse_classing_results)) {
  cat("Variable:", names(coarse_classing_results)[i], "\n")
  df_aux1 <- coarse_classing_results[[i]]
  categoric_label[[names(coarse_classing_results)[i]]] <- df_aux1$Categoria
  plot_woe(coarse_classing_results[[i]], 
           var_name = names(coarse_classing_results)[i])
  cat("\n")
}

```

Nuevas categorías:

```{r}
coarse_classing_results
```

Information Value:

```{r}
iv_factor_var = list()
for(var in  names(coarse_classing_results )){
  df <- coarse_classing_results[[var]]
  iv_factor_var[[var]] <- sum((df$Total_buenos/sum(df$Total_bueno)-df$Total_malos/sum(df$Total_malos))*df$WOE)
}
iv_factor_var
```

```{r}
var_menor_woe <- list()

for (var in names(coarse_classing_results)) {
  df <- coarse_classing_results[[var]]
  
  # Encuentra la fila con el menor valor de WOE
  min_woe_row <- df[df$WOE == min(df$WOE), ]
  
  # Almacena la categoría correspondiente
  var_menor_woe[[var]] <- min_woe_row$Categoria
}
```

##### Creación de variables dummy

```{r}
#1-Grade
d_grade_1=ifelse(datos$grade%in%c("A"),1,0) 
d_grade_2=ifelse(datos$grade%in%c("B"),1,0)
d_grade_3=ifelse(datos$grade%in%c("C"),1,0)
d_grade_4=ifelse(datos$grade%in%c("D"),1,0)
d_grade_5=ifelse(datos$grade%in%c("E","F","G"),1,0)

df1 <- data.frame(d_grade_1,d_grade_2,d_grade_3,d_grade_4,d_grade_5)

#2-Home ownership
d_home_1=ifelse(datos$home_ownership%in%unlist(strsplit("ANY_NONE_OTHER_RENT", "_")),1,0)
d_home_2=ifelse(datos$home_ownership%in%c("OWN"),1,0)
d_home_3=ifelse(datos$home_ownership%in%c("MORTGAGE"),1,0)

df2=data.frame(d_home_1,d_home_2,d_home_3)

#3-Addr state

d_addr_state_1=ifelse(datos$addr_state%in%unlist(strsplit("NE_IA_ID_NV_HI_FL_AL_LA_NY_MD_NC_MO_NM_OK_NJ_VA","_")),1,0)
d_addr_state_2=ifelse(datos$addr_state%in%unlist(strsplit("CA_TN_MI_AZ_RI_OH_MN_PA_KY_MA_DE_UT_IN_AR_GA_WA_ME_WI_SD_OR_TX_CT_SC_IL_CO_MT_AK_KS_MS_VT_NH_WV_WY_DC","_")),1,0)

df3=data.frame(d_addr_state_1,  d_addr_state_2)
             
            
# 4-Verification status

d_ver_1=ifelse(datos$verification_status%in%levels(datos$verification_status)[1],1,0)
d_ver_2=ifelse(datos$verification_status%in%levels(datos$verification_status)[2],1,0)
d_ver_3=ifelse(datos$verification_status%in%levels(datos$verification_status)[3],1,0)

df4<-data.frame(d_ver_1,d_ver_2,d_ver_3)

#5-Purpose
d_pur_1=ifelse(datos$purpose%in%c("small_business","educational","moving","renewable_energy","other","house","medical","vacation","wedding"),1,0)
d_pur_2=ifelse(datos$purpose%in%c("debt_consolidation"),1,0)
d_pur_3=ifelse(datos$purpose%in%c("home_improvement","major_purchase"),1,0)
d_pur_4=ifelse(datos$purpose%in%c("credit_card","car"),1,0)

df5<-data.frame(d_pur_1,d_pur_2,d_pur_3,d_pur_4)

#6-Initial list status

d_list_1=ifelse(datos$initial_list_status%in%levels(datos$initial_list_status)[1],1,0)
d_list_2=ifelse(datos$initial_list_status%in%levels(datos$initial_list_status)[2],1,0)

df6<-data.frame(d_list_1,d_list_2)

#7-Term

d_term_1=ifelse(datos$term%in%levels(datos$term)[1],1,0)
d_term_2=ifelse(datos$term%in%levels(datos$term)[2],1,0)

df7<-data.frame(d_term_1,d_term_2)

#8-Emp length


d_emp_1=ifelse(datos$emp_length%in%c("< 1 year"),1,0)
d_emp_2=ifelse(datos$emp_length%in%unlist(strsplit("1 year_2 years_3 years_4 years","_")),1,0)
d_emp_3=ifelse(datos$emp_length%in%unlist(strsplit("5 years_6 years","_")),1,0)
d_emp_4=ifelse(datos$emp_length%in%unlist(strsplit("7 years_8 years_9 years","_")),1,0)
d_emp_5=ifelse(datos$emp_length%in%c("9+ years"),1,0)

df8<-data.frame(d_emp_1,d_emp_2,d_emp_3,d_emp_4,d_emp_5)

# 8_1 - Inq_last_6mths
d_inq_1=ifelse(datos$inq_last_6mths==0,1,0)
d_inq_2=ifelse(datos$inq_last_6mths==1,1,0)
d_inq_3=ifelse(datos$inq_last_6mths==2,1,0)
d_inq_4=ifelse(!datos$inq_last_6mths%in%c("0","1","2"),1,0)

df8_1<-data.frame(d_inq_1, d_inq_2,d_inq_3,d_inq_4)

```

### Tratamiento de variables continuas

#### Fine Classing

Se crearán entre 10 o 20 grupos para cada variable continua y después se calculará el WOE para luego combinar categorías adyacentes con scores WOE similares.

##### Variable annual_inc (ingreso anual)

Es la variable continua más importante en nuestro estudio. El siguiente histograma sugiere que el Ingreso tiene una distribución sesgada a la derecha. En particular, el 95% de los datos se encuentran por debajo de \`\`{r} quantile(train\$annual_inc,0.95)\`\`\`.

```{r}
library(ggplot2)
library(scales)

ggplot(train, aes(x = annual_inc)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "blue", alpha = 0.5) +
  geom_density(color = "red") +
  scale_x_continuous(labels = dollar) +
  labs(title = "Distribución del ingreso anual", 
       x = "Ingreso anual",
       y = "Densidad") +
  theme_minimal()
  
```

Como la mayoría de los clientes gana menos de ```` {r} round(quantile(train$annual_inc,0.95),0)```, se divirá en bins el intervalo de ingreso de 0 a ````{r} round(quantile(train$annual_inc,0.95),0)```, mientras que otro grupo se conformará por que ganan más que ```{r} round(quantile(train$annual_inc,0.95),0)\`\`\`.

La siguiente Figura muestra el histograma con 50 bins del intervalo de ingreso de 0 al percentil 95.

```{r}
q95<- round(quantile(train$annual_inc,0.95),0)
income_q95 <- train$annual_inc[which(train$annual_inc<=q95)]
#table(cut_income) # Muestra cuántos registros hay por intervalo

#prop.table(table(train$annual_inc))*100  # Indica la proporción (en base a 100) por intervalo del total de datos 

# se guarga en un data frame la variable de respuesta y los bins
cut_income <- cut(income_q95,breaks=50)
income_q95_df <- data.frame(  annual_inc = factor(cut_income , labels =  names(table(cut_income))),
                                y =train$y[which(train$annual_inc<=q95)])

# Crear un histograma de los bins
hist(as.numeric(income_q95_df$annual_inc), 
     col = "lightblue", 
     main = "Histograma de Ingresos (Q95)",
     xlab = "Bins",
     ylab = "Frecuencia")

n_q95 <- length(train$y[which(train$annual_inc>q95)])

income_df <- rbind(income_q95_df,
                  data.frame(
                              annual_inc  = rep("Ingreso_mayor", n_q95),
                              y = train$y[which(train$annual_inc>q95)])
)

```

##### Variable int_rate (Tasa de interés)

La siguiente Figura muestra el histograma con 20 bins.

```{r}
# se guarga en un data frame la variable de respuesta y los bins
cut_rate <- cut(train$int_rate, breaks = 20)
int_rate_df <- data.frame( int_rate = factor(cut_rate , labels =  names(table(cut_rate))),
                            y = train$y)

# Crear un histograma de los bins
hist(as.numeric(int_rate_df$int_rate), 
     col = "lightblue", 
     main = "Histograma de Tasa de Interés",
     xlab = "Bins",
     ylab = "Frecuencia")
```

##### Variables "mths_since_last_delinq" y "mths_since_last_record"

Las variables "mths_since_last_delinq" y "mths_since_last_record" corresponden a los meses desde el último fraude/manejo inadecuado de la cuenta y el número de meses desde el último registro público (ej: bancarrota, sentencias, juicios, ejecuciones hipotecarias, etc.). Estas variables tienen muchos NA, pero no se debe a un error,sino a la naturaleza de la variable, puesto que si no aplica para una persona estas características, el registro de esta persona es vacío. Por lo tanto, los NA se agruparán de manera independiente.

```{r}
cat("Porcentaje de NA para mths_since_last_delinq: ",sum(is.na(train$mths_since_last_delinq))/nrow(train), "\n")

cat("Porcentaje de NA para mths_since_last_record:",sum(is.na(train$mths_since_last_delinq))/nrow(train))
```

Se procede a crear los bins sin los NA.

```{r}
delinq<- train$mths_since_last_delinq[which(is.na(train$mths_since_last_delinq)==FALSE)] #quitando los NA para obtener los no vacíos
record<-train$mths_since_last_record[which(is.na(train$mths_since_last_record)==FALSE)]  #Se quitan los NA para obtener los no vacíos

cut_delinq <-cut(delinq,breaks=20,labels=FALSE)
cut_record <- cut(record,breaks=20,labels=FALSE)
  
delinq_df <- data.frame(mths_since_last_delinq= factor(cut_delinq , labels =  names(table(cut_delinq))),
                        y = train$y[which(is.na(train$mths_since_last_delinq)==FALSE)])

record_df <- data.frame(mths_since_last_record = factor(cut_record, labels =  names(table(cut_record))),
                        y = train$y[which(is.na(train$mths_since_last_record)==FALSE)])

par(mfrow=c(1,2))

# Crear un histograma de los bins
hist(as.numeric(delinq_df$mths_since_last_delinq), 
     col = "lightblue", 
     main = "Histograma de \n mths_since_last_delinq",
     xlab = "Bins",
     ylab = "Frecuencia")

hist(as.numeric(record_df$mths_since_last_record), 
     col = "lightblue", 
     main = "Histograma de \n mths_since_last_record",
     xlab = "Bins",
     ylab = "Frecuencia")

n_na_delinq <- length(train$mths_since_last_delinq[which(is.na(train$mths_since_last_delinq))])
n_na_record <- length(train$mths_since_last_record[which(is.na(train$mths_since_last_record))])

delinq_df_c<- rbind(delinq_df,
                   data.frame(
                              mths_since_last_delinq  = rep("NA", n_na_delinq),
                        y = train$y[which(is.na(train$mths_since_last_delinq))]))

record_df_c<- rbind(record_df,
                   data.frame(
                             mths_since_last_record  = rep("NA", n_na_record),
                        y = train$y[which(is.na(train$mths_since_last_record))]))

```

##### Cálculo del WOE

```{r}
train_numeric_var <- list(
  annual_inc = income_df,
  int_rate = int_rate_df, 
  mths_since_last_delinq = delinq_df_c,
  mths_since_last_record = record_df_c
)

names(train_numeric_var) <- numeric_var

woe_results_numeric_var <- list()
i = 1
for(var_ in numeric_var ){
  woe_results_numeric_var[[var_]]<- calculate_woe(train_numeric_var[[var_,drop=FALSE]] , "y", numeric_var[i])
  i = i + 1
}

# Imprimir los resultados
for (i in 1:length(numeric_var)) {
  cat("Variable:", names(woe_results_numeric_var)[i], "\n")
  print(woe_results_numeric_var[[i]][[1]])
  plot_woe(woe_results_numeric_var[[i]][[1]], var_name = names(woe_results_numeric_var)[i])
  cat("\n")
}
```

```{r}
coarse_classing_results_numeric_var <- list()
i = 1
for(var_ in numeric_var ){
  coarse_classing_results_numeric_var[[var_]]<-coarse_classing(train_numeric_var[[var_,drop=FALSE]] , "y", numeric_var[i])
  i = i + 1
}

numeric_label <- list()
# Imprimir los resultados
for (i in 1:length(numeric_var)) {
  cat("Variable:", names(coarse_classing_results_numeric_var)[i], "\n")
  df_aux <- coarse_classing_results_numeric_var[[i]][[1]]
  print( df$Categoria)
  numeric_label[[names(coarse_classing_results_numeric_var)[i]]] <- df_aux$Categoria
  plot_woe(df_aux, 
           var_name = names(coarse_classing_results_numeric_var)[i])
  cat("\n")
}
```

```{r}
coarse_classing_results_numeric_var
```

##### Creación de variables dummy

```{r}
#9- Income 
d_inc_1=ifelse(datos$annual_inc<=as.numeric(4.93e+04),1,0)
d_inc_2=ifelse(datos$annual_inc>as.numeric(4.93e+0) & datos$annual_inc<=as.numeric(5.82e+04),1,0)
d_inc_3=ifelse(datos$annual_inc>as.numeric(5.82e+04) & datos$annual_inc<=as.numeric(6.11e+04),1,0)
d_inc_4=ifelse(datos$annual_inc>as.numeric(6.11e+04) & datos$annual_inc<=150000,1,0)
d_inc_5=ifelse(datos$annual_inc>150000,1,0)

df9<-d_int<-data.frame(d_inc_1,d_inc_2,d_inc_3, d_inc_4, d_inc_5)


#10- Int_rate
d_int_1=ifelse(datos$int_rate<=7.48,1,0)
d_int_2=ifelse(datos$int_rate >7.48 & datos$int_rate<=8.52 ,1,0)
d_int_3=ifelse(datos$int_rate>8.52 & datos$int_rate<=9.55,1,0)
d_int_4=ifelse(datos$int_rate>9.55 & datos$int_rate<=10.6,1,0)
d_int_5=ifelse(datos$int_rate>10.6 & datos$int_rate<=11.6,1,0)
d_int_6=ifelse(datos$int_rate>11.6 & datos$int_rate<=12.6,1,0)
d_int_7=ifelse(datos$int_rate>12.6 & datos$int_rate<=13.7,1,0)
d_int_8=ifelse(datos$int_rate>13.7 & datos$int_rate<=14.7,1,0)
d_int_9=ifelse(datos$int_rate>14.7 & datos$int_rate<=15.7,1,0)
d_int_10=ifelse(datos$int_rate>15.7 & datos$int_rate<=16.8,1,0)
d_int_11=ifelse(datos$int_rate>16.8,1,0)

df10<-data.frame(d_int_1,d_int_2,d_int_3, d_int_4, d_int_5, d_int_6,
                  d_int_7,d_int_8,d_int_9,d_int_10,d_int_11)


#11- mths_since_last_delinq

d_delinq_1=ifelse(is.na(datos$mths_since_last_delinq),1,0)
d_delinq_2=ifelse(!is.na(datos$mths_since_last_delinq) &
                                    datos$mths_since_last_delinq == 1,1,0)
d_delinq_3=ifelse(!is.na(datos$mths_since_last_delinq) &
                                    datos$mths_since_last_delinq == 2,1,0) 
d_delinq_4=ifelse(!is.na(datos$mths_since_last_delinq) &
                                    datos$mths_since_last_delinq == 3,1,0) 
d_delinq_5=ifelse(!is.na(datos$mths_since_last_delinq) &
                                    datos$mths_since_last_delinq == 4,1,0) 
d_delinq_6=ifelse(!is.na(datos$mths_since_last_delinq) &
                                    datos$mths_since_last_delinq > 4,1,0) 

df11<-data.frame(d_delinq_1,d_delinq_2,d_delinq_3,d_delinq_4,d_delinq_5,d_delinq_6)
                                     
                                     
                                     
                        
#12- mths_since_last_record

d_record_1=ifelse(is.na(datos$mths_since_last_record),1,0)
d_record_2=ifelse(!is.na(datos$mths_since_last_record),1,0) 

df12<-data.frame(d_record_1,d_record_2)

```

### Creación del modelo

```{r}
d_bueno_malo=datos$y

# Base de datos con las variables dummy
dummy<-cbind(datos$member_id,d_bueno_malo,df1,df2,df3,df4,df5,df6,df7,df8,df8_1,df9, df10,df11,df12)

#write.csv(dummy,"base_dummy.csv")

# Base de registros train con las variables dummy
dum_train=dummy[which(datos$member_id%in%train$member_id==TRUE),]
dum_train = dum_train[,-1]
# Base de registros train con las variables dummy
dum_test=dummy[which(datos$member_id%in%test$member_id==TRUE),]
dum_test = dum_test[,-1]
#write.csv(dummy_train,"dummy_train.csv")
dummy$d_bueno_malo <- as.numeric(dummy$d_bueno_malo)
dum_train$d_bueno_malo <- as.numeric(dum_train$d_bueno_malo)
dum_test$d_bueno_malo <- as.numeric(dum_test$d_bueno_malo)
```

Proceso de creación del modelo de regresión logística

Para cada cada variable, no se considera la variable dummy de menor WOE, con el fin de evitar colinearidad.

```{r}
dum_train_m<-subset(dum_train,select = -c(datos$member_id,d_grade_1,d_home_3,d_addr_state_2,d_ver_3,d_pur_4,d_list_1,d_term_2,d_emp_5,d_inq_1,d_int_1,d_inc_5,d_delinq_5,d_record_1))
names(dum_train_m)
```

```{r}
#Creación del model con todas las variables predictoras posibles:
model_1=glm(d_bueno_malo~.,family = binomial(link ="logit"),data=dum_train_m)
summary(model_1)
```

Ajuste sin la variable Home:

```{r}
# Creación del modelo con variables significativas
model_2=glm(d_bueno_malo~.,family = binomial(link ="logit"),
            data= dum_train_m[, !colnames(dum_train_m) %in% c("d_home_1", "d_home_2")])

summary(model_2)
```

Se escoge el primer modelo por tener el menor AIC.

### Análisis de residuales

```{r}
par(mfrow = c(2,2))
plot(model_1)
```

### Comprobación del modelo

```{r}
#Creación de una subbase de la matriz dummy test con las variables significativas

dum_test_signif<-subset(dum_test,select = -c(datos$member_id,d_grade_1,d_home_3,d_addr_state_2,d_ver_3,d_pur_4,d_list_1,d_term_2,d_emp_5,d_inq_1,d_int_1,d_inc_5,d_delinq_5,d_record_1))

# Predicción de probabilidades para la base test:
predicciones<-predict(model_1,newdata=dum_test_signif,type="response")
dum_test_signif$predicciones=predicciones #Creando la columna de probabilidades


```

#### Realización de la curva ROC

```{r}
##### Realizaci?n de la curva ROC
library(ROCit)
curva_roc=(rocit(dum_test_signif$predicciones,dum_test_signif$d_bueno_malo))
plot(curva_roc,YIndex=FALSE,legend=FALSE)
summary(curva_roc)
names(curva_roc)
print(auc<-curva_roc$AUC)
```

Índice de Youden:

```{r}
tabla=data.frame(curva_roc$Cutoff,curva_roc$TPR,curva_roc$FPR)
tabla$esp=1-curva_roc$FPR               
tabla$youden_index=tabla$curva_roc.TPR+ tabla$esp-1
print(optimal_point<-tabla[which(tabla$youden_index==max(tabla$youden_index)),1])
```

Coeficiente de Gini:

```{r}
#coeficiente de Gini
print(Gini<-2*auc-1)
```

#### Densidades

```{r}
pred=subset(dum_test_signif, select=c(d_bueno_malo,predicciones))
pred$clase=as.factor(pred$d_bueno_malo)
ggplot(pred, aes(predicciones, col=clase, fill=clase)) + geom_density(alpha=.5)+
labs(x = "Probabilidad de Incumplimiento", y = "Densidad")
```

#### Grafico de kolmogorov-smirnov

```{r}
ks=ksplot(curva_roc,legend=FALSE)
estadistico_ks=ks$`KS stat`
```

Región de rechazo:

```{r}
nt_good <-sum(dum_test$d_bueno_malo)
nt_bad <-length(dum_test$d_bueno_malo)-sum(dum_test$d_bueno_malo)
1.36*sqrt((nt_good +nt_bad )/(nt_bad *nt_good))
```

##### Realización de la curva CAP

```{r}
analisis_gini=subset(dum_test_signif, select=c(d_bueno_malo,predicciones))
analisis_gini2=analisis_gini[order(analisis_gini$predicciones),]
analisis_gini2$cum_todos=seq(1,dim(analisis_gini2)[1])/dim(analisis_gini2)[1]
analisis_gini2$malos1buenos0=ifelse(analisis_gini2$d_bueno_malo==1,0,1)
analisis_gini2$cum_malos=cumsum(analisis_gini2$malos1buenos0)/sum(analisis_gini2$malos1buenos0)
plot(analisis_gini2$cum_todos,analisis_gini2$cum_malos,type="l") 
abline(0,1)
analisis_gini2$cum_malostotales=1
analisis_gini2$cum_malostotales[1:sum(analisis_gini2$malos1buenos0)]=seq(1,sum(analisis_gini2$malos1buenos0))/sum(analisis_gini2$malos1buenos0)
names(analisis_gini2)

library(ggplot2) #Librer?a para graficar
ggplot(analisis_gini2)+ geom_line(aes(x=cum_todos,y=cum_todos),col="blue3")+
  geom_line(aes(x=cum_todos,y=cum_malos),col="deeppink")+
  geom_line(aes(x=cum_todos,y=cum_malostotales),col="darkmagenta")+
  labs(x="Porcentaje acumulado del total",y="Porcentaje acumulado de malos")
```

#### Scores

Estableciendo el mínimo y máximo score:

```{r}
min_score=30
max_score=850

```

Proceso para calcular la suma de los mínimos coeficientes de cada variable y la suma de los máximos coeficientes:

```{r}
coef=data.frame(c("Intercepto",substr(names(dum_test_signif[,2:42]),3,6)),model_1$coefficients)
names(coef)=c("Variable","Coeficientes")
var_ref_name <- c("d_grade_1","d_home_3","d_addr_state_2","d_ver_3","d_pur_4","d_list_1","d_term_2","d_emp_5","d_inq_1","d_int_1","d_inc_5","d_delinq_5","d_record_1")
var_ref=substr(var_ref_name,3,6)
coef=rbind(coef,data.frame("Variable"=var_ref,"Coeficientes"=rep(0,length(var_ref))))
library(plyr)
listc=split(coef,coef$Variable)
c<-sapply(listc,"[","Coeficientes")

min_coef <- rep(0,length(c))
max_coef <- rep(0,length(c))
min_sum_coef=0
max_sum_coef=0
for ( i in 1:length(c)){
  min_coef[i] <- min(unlist(c[[i]]))
  min_sum_coef=min_sum_coef +min(unlist(c[[i]]))
  max_coef[i] <- max(unlist(c[[i]]))
  max_sum_coef=max_sum_coef +max(unlist(c[[i]]))
}

#names(c) <-c("addr_state" ,"mths_since_last_delinq" , "emp_length", "grade","home_ownership","annual_inc","inq_last_6mths","int_rate" ,"Intercepto",
 #            "initial_list_status","purpose","mths_since_last_record","term" ,"verification_status")


```

Tabla de Scores

```{r}

coef2 <- coef[1:42,] 

min_max_coef_table <- data.frame("Variable" =sub("\\..*", "", names(c)),
                                 "Min_coeficiente" = min_coef,
                                 "Max_coeficiente" = max_coef)

scores_ <- left_join(coef2, min_max_coef_table, by = "Variable")
scores_ <-cbind (scores_, "Score"=0)


scores_[1,"Score"] <-((scores_[1,"Coeficientes"] - min_sum_coef)/(max_sum_coef-min_sum_coef))*(max_score-min_score)+min_score
scores_[-1,"Score"] <-scores_[-1,"Coeficientes"]*((max_score-min_score)/(max_sum_coef-min_sum_coef))
scores_$Variable <- rownames(coef2 )
scores_

```

```{r, echo=FALSE, eval=FALSE}
library(xtable)
print(xtable(scores_[,c("Variable","Coeficientes","Score")]), include.rownames = FALSE)
```

Tabla de mínimos y máximos coeficientes

```{r}
min_max_coef_table$Variable <- c("addr_state" ,"mths_since_last_delinq" , "emp_length", "grade","home_ownership","annual_inc","inq_last_6mths","int_rate" ,"Intercepto",
             "initial_list_status","purpose","mths_since_last_record","term" ,"verification_status")
min_max_coef_table
```

```{r, echo=FALSE, eval=FALSE}
library(xtable)
print(xtable(min_max_coef_table), include.rownames = FALSE)
```

Creación de un data frame con las probabilidades representadas como scores:

```{r}
score_cutoff=data.frame(curva_roc$Cutoff,curva_roc$FPR, curva_roc$TPR)
names(score_cutoff)=c("Threshold","FPR","TPR")

#Convirtiendo los probabilidades en scores:
prob_as_score=(log(score_cutoff$Threshold/(1-score_cutoff$Threshold))-min_sum_coef)*((max_score-min_score)/(max_sum_coef-min_sum_coef))+ min_score
scoreaprob=round(prob_as_score)
scoreaprob[1]=850
score_cutoff$Threshold[1]=1
score_cutoff$Score=scoreaprob
####

#Calculando tasas de aprobaci?n y rechazo
prob=rep(0,dim(score_cutoff)[1])
for (i in 1:dim(score_cutoff)[1]){prob[i]=length(which(predicciones>=score_cutoff$Threshold[i]))}
score_cutoff$Aprobados=prob
score_cutoff$Rechazados=dim(score_cutoff)[1]-score_cutoff$Aprobados
score_cutoff$Tasa_Aprob=score_cutoff$Aprobados/dim(score_cutoff)[1]
score_cutoff$Tasa_Rechazo=score_cutoff$Rechazados/dim(score_cutoff)[1]

#Creando una tabla para 10 probabilidades
top=matrix(1:8,1,8)
colnames(top)=colnames(score_cutoff)
cuenta=rep(0,10)
for(i in 1: 10){
  basex=score_cutoff[which(score_cutoff$Threshold> 1-(0.01)*i),] 
  top=rbind(top,basex[dim(basex)[1],])
  cuenta[i]=length(predicciones[which(predicciones>=top[i+1,1])])
}

top=top[-1,]
top$PD=c("1%","2%","3%","4%","5%","6%","7%","8%","9%","10%")
top=subset(top,select=c("PD","Score","Tasa_Aprob","Tasa_Rechazo"))

library(dplyr) #Librería para manejar un data frame
top_new<-top%>%
  mutate(Tasa_Aprob1000=Tasa_Aprob*1000,Tasa_Rechazo1000=Tasa_Rechazo*1000)
```

```{r}
top_new
```

```{r, echo=FALSE, eval=FALSE}
library(xtable)
print(xtable(top_new), include.rownames = FALSE)
```

#### Matriz de confusión

```{r}
library("caret")
threshold_ <-  0.7
predicciones_test <- as.factor(ifelse(dum_test_signif$predicciones> threshold_, yes = 1, no = 0))
matriz<-confusionMatrix(as.factor(dum_test_signif$d_bueno_malo),as.factor(predicciones_test)  )
matriz
```
